{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# gensim modules\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# random\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, sources):\n",
    "        self.sources = sources\n",
    "        \n",
    "        flipped = {}\n",
    "        \n",
    "        # make sure that keys are unique\n",
    "        for key, value in sources.items():\n",
    "            if value not in flipped:\n",
    "                flipped[value] = [key]\n",
    "            else:\n",
    "                raise Exception('Non-unique prefix encountered')\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    yield LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no])\n",
    "    \n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no]))\n",
    "        return self.sentences\n",
    "    \n",
    "    def sentences_perm(self):\n",
    "        shuffled = list(self.sentences)\n",
    "        random.shuffle(shuffled)\n",
    "        return shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources = {'test-neg.txt':'TEST_NEG', 'test-pos.txt':'TEST_POS', 'train-neg.txt':'TRAIN_NEG', 'train-pos.txt':'TRAIN_POS', 'train-unsup.txt':'TRAIN_UNS'}\n",
    "\n",
    "sentences = LabeledLineSentence(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(min_count=1, window=10, size=128, sample=1e-4, negative=5, workers=7)\n",
    "\n",
    "model.build_vocab(sentences.to_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100006\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print(token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87261865"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences.sentences_perm(), total_examples=token_count, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.6629217863082886),\n",
       " ('decent', 0.6190322637557983),\n",
       " ('nice', 0.5878570079803467),\n",
       " ('fine', 0.5873998403549194),\n",
       " ('bad', 0.5638591051101685),\n",
       " ('solid', 0.5198214650154114),\n",
       " ('excellent', 0.49024176597595215),\n",
       " ('workable', 0.4608621895313263),\n",
       " ('alright', 0.45717692375183105),\n",
       " ('terrific', 0.4457021653652191)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.37049055e+00,  -3.71870637e-01,   1.71233439e+00,\n",
       "        -3.49776626e-01,   1.46382880e+00,   5.57693601e-01,\n",
       "         1.70993924e+00,   1.20419049e+00,  -1.01734400e+00,\n",
       "         1.73735666e+00,   1.28781945e-01,  -8.40478241e-01,\n",
       "        -4.64325696e-01,  -6.96763396e-02,   1.57788157e+00,\n",
       "        -3.61901671e-01,   6.56533360e-01,  -1.29465508e+00,\n",
       "         4.51561004e-01,   3.26383471e-01,  -1.20201170e+00,\n",
       "        -3.75328362e-01,   1.68469989e+00,  -1.55048206e-01,\n",
       "         8.96417975e-01,   6.68684781e-01,   1.80388466e-01,\n",
       "        -5.56801930e-02,   3.49873334e-01,   4.28469814e-02,\n",
       "         2.35215783e+00,  -8.74150872e-01,   7.81498432e-01,\n",
       "         3.36278200e-01,  -1.74268186e-02,  -3.44305158e-01,\n",
       "         6.71895742e-02,  -6.04222119e-01,   7.18841553e-01,\n",
       "        -1.32454491e+00,  -1.50396180e+00,  -2.20189977e+00,\n",
       "         4.82800715e-02,   7.98003748e-02,  -7.61350334e-01,\n",
       "         2.38305733e-01,   2.84754246e-01,  -2.27010295e-01,\n",
       "        -4.15499091e-01,   5.56991279e-01,   1.26399934e+00,\n",
       "         1.07099628e+00,   1.41655910e+00,   8.15841019e-01,\n",
       "        -6.87876523e-01,  -9.03578699e-02,  -6.62107646e-01,\n",
       "         5.83838701e-01,  -6.12215638e-01,  -3.36348719e-04,\n",
       "         4.76941466e-01,   1.52300262e+00,   5.86753964e-01,\n",
       "         4.63297218e-01,  -2.31645644e-01,  -1.46806824e+00,\n",
       "        -9.52314317e-01,  -5.25766075e-01,  -1.26686454e+00,\n",
       "         7.90450871e-01,  -1.62182522e+00,   4.82424557e-01,\n",
       "        -1.39643535e-01,   7.20825613e-01,  -7.28931963e-01,\n",
       "        -2.75161475e-01,   2.19683957e+00,   1.25065178e-01,\n",
       "         5.25002539e-01,   2.59794760e+00,  -3.34027618e-01,\n",
       "        -1.28468359e+00,   6.42024934e-01,   1.38843966e+00,\n",
       "        -2.58775759e+00,  -6.62859380e-01,  -5.14583945e-01,\n",
       "        -1.14804709e+00,  -4.24008101e-01,   4.23480690e-01,\n",
       "         7.59780705e-01,   7.87471890e-01,  -3.82137209e-01,\n",
       "         1.20961094e+00,   1.62923872e+00,   1.18783045e+00,\n",
       "        -1.74711466e+00,   5.42026341e-01,   7.91615725e-01,\n",
       "         1.42172587e+00,   1.61742494e-01,  -8.60670805e-01,\n",
       "        -2.93945551e-01,   8.68931055e-01,   4.43344951e-01,\n",
       "        -1.31513894e+00,  -5.77159524e-01,  -8.17620218e-01,\n",
       "         4.77656335e-01,   3.27448249e-01,  -6.56754803e-03,\n",
       "         1.11037755e+00,  -4.82446641e-01,  -1.77039421e+00,\n",
       "        -2.95849466e+00,  -6.01359129e-01,  -2.37182975e-01,\n",
       "         2.92191021e-02,  -1.77349699e+00,  -8.90921593e-01,\n",
       "        -7.36336827e-01,   2.59851426e-01,  -1.61028576e+00,\n",
       "         3.71473953e-02,  -1.47487819e+00,  -4.54812646e-02,\n",
       "         4.27096665e-01,  -1.63045514e+00], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['nice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('./imdb.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec.load('./imdb.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['once', 'again', 'mr', 'costner', 'has', 'dragged', 'out', 'a', 'movie', 'for', 'far', 'longer', 'than', 'necessary', 'aside', 'from', 'the', 'terrific', 'sea', 'rescue', 'sequences', 'of', 'which', 'there', 'are', 'very', 'few', 'i', 'just', 'did', 'not', 'care', 'about', 'any', 'of', 'the', 'characters', 'most', 'of', 'us', 'have', 'ghosts', 'in', 'the', 'closet', 'and', 'costner', 's', 'character', 'are', 'realized', 'early', 'on', 'and', 'then', 'forgotten', 'until', 'much', 'later', 'by', 'which', 'time', 'i', 'did', 'not', 'care', 'the', 'character', 'we', 'should', 'really', 'care', 'about', 'is', 'a', 'very', 'cocky', 'overconfident', 'ashton', 'kutcher', 'the', 'problem', 'is', 'he', 'comes', 'off', 'as', 'kid', 'who', 'thinks', 'he', 's', 'better', 'than', 'anyone', 'else', 'around', 'him', 'and', 'shows', 'no', 'signs', 'of', 'a', 'cluttered', 'closet', 'his', 'only', 'obstacle', 'appears', 'to', 'be', 'winning', 'over', 'costner', 'finally', 'when', 'we', 'are', 'well', 'past', 'the', 'half', 'way', 'point', 'of', 'this', 'stinker', 'costner', 'tells', 'us', 'all', 'about', 'kutcher', 's', 'ghosts', 'we', 'are', 'told', 'why', 'kutcher', 'is', 'driven', 'to', 'be', 'the', 'best', 'with', 'no', 'prior', 'inkling', 'or', 'foreshadowing', 'no', 'magic', 'here', 'it', 'was', 'all', 'i', 'could', 'do', 'to', 'keep', 'from', 'turning', 'it', 'off', 'an', 'hour', 'in']\n"
     ]
    }
   ],
   "source": [
    "sentences_array = sentences.to_array()\n",
    "sentences_dict = {}\n",
    "\n",
    "for i in range(0,len(sentences_array)):\n",
    "    sentences_dict[sentences_array[i][1][0]] = sentences_array[i][0]\n",
    "    \n",
    "print(sentences_dict['TEST_NEG_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "count=0\n",
    "for i in range(12500):\n",
    "    prefix_train_pos = 'TRAIN_POS_' + str(i)\n",
    "    prefix_train_neg = 'TRAIN_NEG_' + str(i)\n",
    "    temp = (np.matrix(model[sentences_dict[prefix_train_pos]]).shape[0])\n",
    "    if count < temp:\n",
    "        count = temp\n",
    "        \n",
    "    temp = (np.matrix(model[sentences_dict[prefix_train_neg]]).shape[0])\n",
    "    if count < temp:\n",
    "        count = temp\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros(shape=(25000, 1000, 128)).astype(np.float32)\n",
    "Y_train = np.zeros(shape=(25000, 1)).astype(np.float32)\n",
    "\n",
    "empty_word = np.zeros(128).astype(np.float32)\n",
    "\n",
    "for i in range(12500):\n",
    "    prefix_train_pos = 'TRAIN_POS_' + str(i)\n",
    "    prefix_train_neg = 'TRAIN_NEG_' + str(i)\n",
    "    len1 = len(sentences_dict[prefix_train_pos])\n",
    "    len2 = len(sentences_dict[prefix_train_neg])\n",
    "    for j in range(1000):\n",
    "        if j < len1:\n",
    "            X_train[i,j,:] = model[sentences_dict[prefix_train_pos][j]]\n",
    "        else:\n",
    "            X_train[i,j,:] = empty_word\n",
    "        \n",
    "        if j < len2: \n",
    "            X_train[12500+i,j,:] = model[sentences_dict[prefix_train_neg][j]]\n",
    "        else:\n",
    "            X_train[12500+i,j,:] = empty_word\n",
    "    \n",
    "    Y_train[i,:] = 1\n",
    "    Y_train[12500 + i,:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.zeros(shape=(25000, 1000, 128)).astype(np.float32)\n",
    "Y_test = np.zeros(shape=(25000, 1)).astype(np.float32)\n",
    "\n",
    "empty_word = np.zeros(128).astype(np.float32)\n",
    "\n",
    "for i in range(12500):\n",
    "    prefix_test_pos = 'TEST_POS_' + str(i)\n",
    "    prefix_test_neg = 'TEST_NEG_' + str(i)\n",
    "    len1 = len(sentences_dict[prefix_test_pos])\n",
    "    len2 = len(sentences_dict[prefix_test_neg])\n",
    "    for j in range(1000):\n",
    "        if j < len1:\n",
    "            X_test[i,j,:] = model[sentences_dict[prefix_test_pos][j]]\n",
    "        else:\n",
    "            X_test[i,j,:] = empty_word\n",
    "        \n",
    "        if j < len2: \n",
    "            X_test[12500+i,j,:] = model[sentences_dict[prefix_test_neg][j]]\n",
    "        else:\n",
    "            X_test[12500+i,j,:] = empty_word\n",
    "    \n",
    "    Y_test[i,:] = 1\n",
    "    Y_test[12500 + i,:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 1000, 32)          12320     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 333, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 333, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 333, 32)           3104      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 333, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 111, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 111, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 111, 32)           3104      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 111, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 37, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 37, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 37, 32)            3104      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 37, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 12, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 12, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 300)               399600    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 301       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 421,533\n",
      "Trainable params: 421,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 378s - loss: 0.4637 - acc: 0.7604 - val_loss: 0.3045 - val_acc: 0.8882\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 482s - loss: 0.3099 - acc: 0.8751 - val_loss: 0.2707 - val_acc: 0.8971\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 477s - loss: 0.2823 - acc: 0.8854 - val_loss: 0.2697 - val_acc: 0.8889\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 481s - loss: 0.2709 - acc: 0.8889 - val_loss: 0.2487 - val_acc: 0.9017\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 478s - loss: 0.2604 - acc: 0.8959 - val_loss: 0.2486 - val_acc: 0.9048\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 479s - loss: 0.2498 - acc: 0.9012 - val_loss: 0.2497 - val_acc: 0.9029\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 472s - loss: 0.2425 - acc: 0.9045 - val_loss: 0.2334 - val_acc: 0.9068\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 485s - loss: 0.2374 - acc: 0.9058 - val_loss: 0.2406 - val_acc: 0.9063\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 474s - loss: 0.2307 - acc: 0.9089 - val_loss: 0.2485 - val_acc: 0.8969\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 485s - loss: 0.2270 - acc: 0.9103 - val_loss: 0.2517 - val_acc: 0.9009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14bd15fd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(1000,128)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(300, dropout=0.2, recurrent_dropout=0.2))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.09%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
